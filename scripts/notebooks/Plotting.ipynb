{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, cohen_kappa_score\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.style.use('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['axes.prop_cycle'] = mpl.cycler(color=colors)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "plt.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-Annotator Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['recipient_problem', 'inadequate_food', 'donor_problem', \n",
    "            'direction_problem','earlier_pickup','system_problem',\n",
    "            'update_contact']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "naveen_file = \"naveen_hierarchical_annotations_2024-05-13_2024-05-19.csv\"\n",
    "jingwu_file = \"jingwu_hierarchical_annotations_2024-05-13_2024-05-19.csv\"\n",
    "naveen_data = pd.read_csv(\"../../results/annotations/\"+naveen_file)\n",
    "jingwu_data = pd.read_csv(\"../../results/annotations/\"+jingwu_file)\n",
    "jingwu_data = jingwu_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "naveen_data['any_donor_problem'] = naveen_data[['inadequate_food', 'donor_problem','earlier_pickup']].max(axis=1)\n",
    "jingwu_data['any_donor_problem'] = jingwu_data[['inadequate_food', 'donor_problem','earlier_pickup']].max(axis=1)\n",
    "\n",
    "naveen_data['any_system_problem'] = naveen_data[['direction_problem', 'system_problem','update_contact']].max(axis=1)\n",
    "jingwu_data['any_system_problem'] = jingwu_data[['direction_problem', 'system_problem','update_contact']].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "jingwu_data = jingwu_data.set_index('id').reindex(naveen_data['id']).reset_index()\n",
    "assert len(jingwu_data) == len(naveen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For task recipient_problem, precision 1.0, recall 0.42857142857142855, F1 0.7142857142857143, kappa 0.5862068965517241\n",
      "For task inadequate_food, precision 0.6956521739130435, recall 1.0, F1 0.8478260869565217, kappa 0.7888942077549066\n",
      "For task donor_problem, precision 0.375, recall 1.0, F1 0.6875, kappa 0.5291479820627802\n",
      "For task direction_problem, precision 0.75, recall 0.75, F1 0.75, kappa 0.7418032786885246\n",
      "For task earlier_pickup, precision 0.6666666666666666, recall 1.0, F1 0.8333333333333333, kappa 0.7961165048543689\n",
      "For task system_problem, precision 0.4, recall 0.6666666666666666, F1 0.5333333333333333, kappa 0.48466257668711665\n",
      "For task update_contact, precision 1.0, recall 1.0, F1 1.0, kappa 1.0\n",
      "For task any_donor_problem, precision 0.6129032258064516, recall 1.0, F1 0.8064516129032258, kappa 0.7048028114017961\n",
      "For task any_system_problem, precision 0.7, recall 0.875, F1 0.7875, kappa 0.760910815939279\n"
     ]
    }
   ],
   "source": [
    "kappa_scores = {}\n",
    "for task in tasks+['any_donor_problem','any_system_problem']:\n",
    "    preds = jingwu_data[task]\n",
    "    labels = naveen_data[task]\n",
    "\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "\n",
    "    kappa = cohen_kappa_score(labels,preds)\n",
    "    kappa_scores[task] = kappa \n",
    "\n",
    "    print(\"For task {}, precision {}, recall {}, F1 {}, kappa {}\".format(task,precision,recall,(precision+recall)/2,kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table = \"\"\"\\\\begin{{table*}}[]\n",
    "\\\\scalebox{{0.85}}{{\n",
    "\\\\begin{{tabular}}{{@{{}}lllll@{{}}}}\n",
    "\\\\toprule\n",
    " & \\\\multicolumn{{4}}{{c}}{{Donor Issues (F1)}}      \\\\\\\\ \\\\cmidrule(lr){{2-5}}\n",
    "                       & Inadequate Food & Earlier Pickup & Other Donor Problem & Any Donor Issue \\\\\\\\ \\\\midrule\n",
    "Kappa Score                & {}            & {}         & {}              & {}             \\\\\\\\ \\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "}}\n",
    "\\\\end{{table*}}\n",
    "\n",
    "\\\\begin{{table*}}[]\n",
    "\\\\scalebox{{0.85}}{{\n",
    "\\\\begin{{tabular}}{{@{{}}lccccc@{{}}}}\n",
    "\\\\toprule\n",
    " & \\\\multicolumn{{1}}{{c}}{{Recipient Issues (F1)}} & \\\\multicolumn{{4}}{{c}}{{Logistical Issues (F1)}}                \\\\\\\\ \\\\cmidrule(lr){{2-2}} \\\\cmidrule(lr){{3-6}}\n",
    "                       & Any Recipient Issue   & Direction Problem & System Problem & Update Contact & Any Logistical Issue    \\\\\\\\ \\\\midrule\n",
    "Kappa Score               & {}                & {}            & {}          & {}        & {}           \\\\\\\\ \\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "}}\n",
    "\\\\end{{table*}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[]\n",
      "\\scalebox{0.85}{\n",
      "\\begin{tabular}{@{}lllll@{}}\n",
      "\\toprule\n",
      " & \\multicolumn{4}{c}{Donor Issues (F1)}      \\\\ \\cmidrule(lr){2-5}\n",
      "                       & Inadequate Food & Earlier Pickup & Other Donor Problem & Any Donor Issue \\\\ \\midrule\n",
      "Kappa Score                & 0.79            & 0.80         & 0.53              & 0.70             \\\\ \\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n",
      "\n",
      "\\begin{table*}[]\n",
      "\\scalebox{0.85}{\n",
      "\\begin{tabular}{@{}lccccc@{}}\n",
      "\\toprule\n",
      " & \\multicolumn{1}{c}{Recipient Issues (F1)} & \\multicolumn{4}{c}{Logistical Issues (F1)}                \\\\ \\cmidrule(lr){2-2} \\cmidrule(lr){3-6}\n",
      "                       & Any Recipient Issue   & Direction Problem & System Problem & Update Contact & Any Logistical Issue    \\\\ \\midrule\n",
      "Kappa Score               & 0.59                & 0.74            & 0.48          & 1.00        & 0.76           \\\\ \\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_formats = []\n",
    "task_list = ['inadequate_food','earlier_pickup','donor_problem','any_donor_problem']#\n",
    "for task in task_list:\n",
    "    all_formats.append(\"%.2f\"% kappa_scores[task])\n",
    "task_list = ['recipient_problem','direction_problem','system_problem','update_contact','any_system_problem']\n",
    "for task in task_list:\n",
    "    all_formats.append(\"%.2f\"% kappa_scores[task])\n",
    "print(table.format(*all_formats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model gpt-4o-mini\n",
      "For task recipient_problem, precision 0.3, recall 0.6, F1 0.44999999999999996, accuracy 0.9285714285714286\n",
      "For task inadequate_food, precision 0.72, recall 1.0, F1 0.86, accuracy 0.9444444444444444\n",
      "For task donor_problem, precision 0.5, recall 0.7777777777777778, F1 0.6388888888888888, accuracy 0.9285714285714286\n",
      "For task direction_problem, precision 0.5714285714285714, recall 1.0, F1 0.7857142857142857, accuracy 0.9761904761904762\n",
      "For task earlier_pickup, precision 0.6666666666666666, recall 1.0, F1 0.8333333333333333, accuracy 0.9761904761904762\n",
      "For task system_problem, precision 0.5, recall 1.0, F1 0.75, accuracy 0.9920634920634921\n",
      "For task update_contact, precision 1.0, recall 0.6666666666666666, F1 0.8333333333333333, accuracy 0.9920634920634921\n",
      "For task any_donor_problem, precision 0.6818181818181818, recall 0.967741935483871, F1 0.8247800586510263, accuracy 0.8809523809523809\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2024-05-20\"\n",
    "end_date = \"2024-05-26\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "all_predictions = {}\n",
    "\n",
    "for model in ['gpt-4o-mini']:\n",
    "    print()\n",
    "    print(\"Model {}\".format(model))\n",
    "    data[model] = {}\n",
    "    validation_labels = pd.read_csv('../../results/annotations/naveen_hierarchical_annotations_{}_{}.csv'.format(start_date,end_date))\n",
    "    validation_predictions = pd.read_csv('../../results/reports/labeled_feedbacks_{}_{}_{}.csv'.format(start_date,end_date,model))\n",
    "    validation_predictions = validation_predictions.fillna(0)\n",
    "    validation_predictions[tasks] = validation_predictions[tasks].astype(int)\n",
    "    validation_predictions['any_donor_problem'] = validation_predictions[['inadequate_food', 'donor_problem','earlier_pickup']].max(axis=1)\n",
    "    validation_labels['any_donor_problem'] = validation_labels[['inadequate_food', 'donor_problem','earlier_pickup']].max(axis=1)\n",
    "    validation_labels['any_problem'] = validation_labels[tasks].max(axis=1)\n",
    "    validation_predictions['any_problem'] = validation_predictions[tasks].max(axis=1)\n",
    "    validation_predictions = validation_predictions.set_index('rescue_id').reindex(validation_labels['id']).reset_index()\n",
    "\n",
    "    all_predictions[model] = {}\n",
    "    if model == 'gpt-4o':\n",
    "        data['ensemble'] = {}\n",
    "\n",
    "    for task in tasks+['any_donor_problem']:\n",
    "        preds = validation_predictions[task]\n",
    "        labels = validation_labels[task]\n",
    "\n",
    "        if model == 'gpt-4o':\n",
    "            combined_preds = preds * all_predictions['gpt-4o-mini'][task] * all_predictions['gpt-3.5-turbo'][task]\n",
    "            precision = precision_score(labels, combined_preds)\n",
    "            recall = recall_score(labels, combined_preds)\n",
    "            data['ensemble'][task] = (precision+recall)/2\n",
    "\n",
    "\n",
    "\n",
    "        all_predictions[model][task] = preds\n",
    "        \n",
    "        precision = precision_score(labels, preds)\n",
    "        recall = recall_score(labels, preds)\n",
    "        data[model][task] = (precision+recall)/2\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        print(\"For task {}, precision {}, recall {}, F1 {}, accuracy {}\".format(task,precision,recall,(precision+recall)/2,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model gpt-3.5-turbo\n",
      "For task recipient_problem, precision 0.3, recall 0.8571428571428571, F1 0.5785714285714285, accuracy 0.8809523809523809\n",
      "For task inadequate_food, precision 0.5769230769230769, recall 0.9375, F1 0.7572115384615384, accuracy 0.9047619047619048\n",
      "For task donor_problem, precision 0.14285714285714285, recall 1.0, F1 0.5714285714285714, accuracy 0.8571428571428571\n",
      "For task direction_problem, precision 0.4444444444444444, recall 1.0, F1 0.7222222222222222, accuracy 0.9603174603174603\n",
      "For task earlier_pickup, precision 0.3333333333333333, recall 1.0, F1 0.6666666666666666, accuracy 0.9682539682539683\n",
      "For task system_problem, precision 0.6, recall 1.0, F1 0.8, accuracy 0.9841269841269841\n",
      "For task update_contact, precision 0.125, recall 1.0, F1 0.5625, accuracy 0.9444444444444444\n",
      "For task any_donor_problem, precision 0.4523809523809524, recall 1.0, F1 0.7261904761904762, accuracy 0.8174603174603174\n",
      "For task donor_other, precision 0.09090909090909091, recall 1.0, F1 0.5454545454545454, accuracy 0.9206349206349206\n",
      "For task any_system_problem, precision 0.4, recall 1.0, F1 0.7, accuracy 0.9047619047619048\n",
      "\n",
      "Model gpt-4o-mini\n",
      "For task recipient_problem, precision 0.5555555555555556, recall 0.7142857142857143, F1 0.6349206349206349, accuracy 0.9523809523809523\n",
      "For task inadequate_food, precision 0.6153846153846154, recall 1.0, F1 0.8076923076923077, accuracy 0.9206349206349206\n",
      "For task donor_problem, precision 0.15789473684210525, recall 1.0, F1 0.5789473684210527, accuracy 0.873015873015873\n",
      "For task direction_problem, precision 0.6666666666666666, recall 1.0, F1 0.8333333333333333, accuracy 0.9841269841269841\n",
      "For task earlier_pickup, precision 0.6666666666666666, recall 1.0, F1 0.8333333333333333, accuracy 0.9920634920634921\n",
      "For task system_problem, precision 0.6, recall 1.0, F1 0.8, accuracy 0.9841269841269841\n",
      "For task update_contact, precision 0.2, recall 1.0, F1 0.6, accuracy 0.9682539682539683\n",
      "For task any_donor_problem, precision 0.4523809523809524, recall 1.0, F1 0.7261904761904762, accuracy 0.8174603174603174\n",
      "For task donor_other, precision 0.07692307692307693, recall 1.0, F1 0.5384615384615384, accuracy 0.9047619047619048\n",
      "For task any_system_problem, precision 0.7272727272727273, recall 1.0, F1 0.8636363636363636, accuracy 0.9761904761904762\n",
      "\n",
      "Model gpt-4o-mini_self_reflection\n",
      "For task recipient_problem, precision 0.5555555555555556, recall 0.7142857142857143, F1 0.6349206349206349, accuracy 0.9523809523809523\n",
      "For task inadequate_food, precision 0.6, recall 0.9375, F1 0.76875, accuracy 0.9126984126984127\n",
      "For task donor_problem, precision 0.125, recall 0.6666666666666666, F1 0.3958333333333333, accuracy 0.8809523809523809\n",
      "For task direction_problem, precision 0.5714285714285714, recall 1.0, F1 0.7857142857142857, accuracy 0.9761904761904762\n",
      "For task earlier_pickup, precision 0.6666666666666666, recall 1.0, F1 0.8333333333333333, accuracy 0.9920634920634921\n",
      "For task system_problem, precision 0.6, recall 1.0, F1 0.8, accuracy 0.9841269841269841\n",
      "For task update_contact, precision 0.25, recall 1.0, F1 0.625, accuracy 0.9761904761904762\n",
      "For task any_donor_problem, precision 0.46153846153846156, recall 0.9473684210526315, F1 0.7044534412955465, accuracy 0.8253968253968254\n",
      "For task donor_other, precision 0.0, recall 0.0, F1 0.0, accuracy 0.9047619047619048\n",
      "For task any_system_problem, precision 0.7272727272727273, recall 1.0, F1 0.8636363636363636, accuracy 0.9761904761904762\n",
      "\n",
      "Model gpt-4o\n",
      "For task recipient_problem, precision 0.5454545454545454, recall 0.8571428571428571, F1 0.7012987012987013, accuracy 0.9523809523809523\n",
      "For task inadequate_food, precision 0.64, recall 1.0, F1 0.8200000000000001, accuracy 0.9285714285714286\n",
      "For task donor_problem, precision 0.13333333333333333, recall 0.6666666666666666, F1 0.39999999999999997, accuracy 0.8888888888888888\n",
      "For task direction_problem, precision 0.8, recall 1.0, F1 0.9, accuracy 0.9920634920634921\n",
      "For task earlier_pickup, precision 0.6666666666666666, recall 1.0, F1 0.8333333333333333, accuracy 0.9920634920634921\n",
      "For task system_problem, precision 0.75, recall 1.0, F1 0.875, accuracy 0.9920634920634921\n",
      "For task update_contact, precision 1.0, recall 1.0, F1 1.0, accuracy 1.0\n",
      "For task any_donor_problem, precision 0.47368421052631576, recall 0.9473684210526315, F1 0.7105263157894737, accuracy 0.8333333333333334\n",
      "For task donor_other, precision 0.0, recall 0.0, F1 0.0, accuracy 0.9126984126984127\n",
      "For task any_system_problem, precision 0.8888888888888888, recall 1.0, F1 0.9444444444444444, accuracy 0.9920634920634921\n",
      "\n",
      "Model llama\n",
      "For task recipient_problem, precision 0.09230769230769231, recall 0.8571428571428571, F1 0.4747252747252747, accuracy 0.5238095238095238\n",
      "For task inadequate_food, precision 0.20634920634920634, recall 0.8125, F1 0.5094246031746031, accuracy 0.5793650793650794\n",
      "For task donor_problem, precision 0.04225352112676056, recall 1.0, F1 0.5211267605633803, accuracy 0.4603174603174603\n",
      "For task direction_problem, precision 0.036585365853658534, recall 0.75, F1 0.3932926829268293, accuracy 0.36507936507936506\n",
      "For task earlier_pickup, precision 0.03225806451612903, recall 1.0, F1 0.5161290322580645, accuracy 0.5238095238095238\n",
      "For task system_problem, precision 0.0625, recall 1.0, F1 0.53125, accuracy 0.6428571428571429\n",
      "For task update_contact, precision 0.0, recall 0.0, F1 0.0, accuracy 0.8809523809523809\n",
      "For task any_donor_problem, precision 0.19791666666666666, recall 1.0, F1 0.5989583333333334, accuracy 0.3888888888888889\n",
      "For task donor_other, precision 0.0, recall 0.0, F1 0.0, accuracy 0.9206349206349206\n",
      "For task any_system_problem, precision 0.06593406593406594, recall 0.75, F1 0.40796703296703296, accuracy 0.30952380952380953\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2024-05-13\"\n",
    "end_date = \"2024-05-19\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "all_predictions = {}\n",
    "\n",
    "for model in ['gpt-3.5-turbo','gpt-4o-mini','gpt-4o-mini_self_reflection','gpt-4o','llama']:\n",
    "    print()\n",
    "    print(\"Model {}\".format(model))\n",
    "    data[model] = {}\n",
    "    validation_labels = pd.read_csv('../../results/annotations/naveen_hierarchical_annotations_{}_{}.csv'.format(start_date,end_date))\n",
    "    validation_predictions = pd.read_csv('../../results/reports/labeled_feedbacks_{}_{}_{}.csv'.format(start_date,end_date,model))\n",
    "    validation_predictions = validation_predictions.fillna(0)\n",
    "\n",
    "    validation_predictions[tasks] = validation_predictions[tasks].astype(int)\n",
    "\n",
    "    validation_predictions['any_donor_problem'] = validation_predictions[['inadequate_food', 'donor_problem','earlier_pickup']].max(axis=1)\n",
    "    validation_labels['any_donor_problem'] = validation_labels[['inadequate_food', 'donor_problem','earlier_pickup']].max(axis=1)\n",
    "\n",
    "    validation_predictions['any_system_problem'] = validation_predictions[['direction_problem', 'system_problem','update_contact']].max(axis=1)\n",
    "    validation_labels['any_system_problem'] = validation_labels[['direction_problem', 'system_problem','update_contact']].max(axis=1)\n",
    "\n",
    "    validation_labels['any_problem'] = validation_labels[tasks].max(axis=1)\n",
    "    validation_predictions['any_problem'] = validation_predictions[tasks].max(axis=1)\n",
    "\n",
    "    validation_labels['donor_other'] = validation_labels['any_donor_problem'] & ~(validation_labels['inadequate_food'] | validation_labels['earlier_pickup'])\n",
    "    validation_predictions['donor_other'] = validation_predictions['any_donor_problem'] & ~(validation_predictions['inadequate_food'] | validation_predictions['earlier_pickup'])\n",
    "\n",
    "    validation_predictions = validation_predictions.set_index('rescue_id').reindex(validation_labels['id']).reset_index()\n",
    "\n",
    "    all_predictions[model] = {}\n",
    "    if model == 'gpt-4o':\n",
    "        data['ensemble'] = {}\n",
    "\n",
    "    for task in tasks+['any_donor_problem','donor_other','any_system_problem']:\n",
    "        preds = validation_predictions[task]\n",
    "        labels = validation_labels[task]\n",
    "\n",
    "        if model == 'gpt-4o':\n",
    "            combined_preds = preds * all_predictions['gpt-4o-mini'][task] * all_predictions['gpt-3.5-turbo'][task]\n",
    "            precision = precision_score(labels, combined_preds)\n",
    "            recall = recall_score(labels, combined_preds)\n",
    "            data['ensemble'][task] = (precision+recall)/2\n",
    "\n",
    "        all_predictions[model][task] = preds\n",
    "        \n",
    "        precision = precision_score(labels, preds)\n",
    "        recall = recall_score(labels, preds)\n",
    "        data[model][task] = (precision+recall)/2\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        print(\"For task {}, precision {}, recall {}, F1 {}, accuracy {}\".format(task,precision,recall,(precision+recall)/2,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"\"\"\\\\begin{{table*}}[]\n",
    "\\\\scalebox{{0.85}}{{\n",
    "\\\\begin{{tabular}}{{@{{}}lllll@{{}}}}\n",
    "\\\\toprule\n",
    "\\\\multirow{{2}}{{*}}{{Model}} & \\\\multicolumn{{4}}{{c}}{{Donor Issues (F1)}}      \\\\\\\\ \\\\cmidrule(lr){{2-5}}\n",
    "                       & Inadequate Food & Earlier Pickup & Other Donor Problem & Any Donor Issue \\\\\\\\ \\\\midrule\n",
    "Llama 3                & {}            & {}         & {}              & {}         \\\\\\\\\n",
    "GPT 3.5 Turbo          & {}            & {}         & {}              & {}            \\\\\\\\\n",
    "GPT 4o Mini            & {}            & {}         & {}              & {}           \\\\\\\\\n",
    "GPT 4o                 & {}            & {}         & {}              & {}             \\\\\\\\ \\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "}}\n",
    "\\\\end{{table*}}\n",
    "\n",
    "\\\\begin{{table*}}[]\n",
    "\\\\scalebox{{0.85}}{{\n",
    "\\\\begin{{tabular}}{{@{{}}lccccccc@{{}}}}\n",
    "\\\\toprule\n",
    "\\\\multirow{{2}}{{*}}{{Model}} & \\\\multicolumn{{1}}{{c}}{{Recipient Issues (F1)}} & \\\\multicolumn{{4}}{{c}}{{Logistical Issues (F1)}} & \\\\multicolumn{{2}}{{c}}{{Other Info}}                   \\\\\\\\ \\\\cmidrule(lr){{2-2}} \\\\cmidrule(lr){{3-6}} \\\\cmidrule(lr){{7-8}}\n",
    "                       & Any Recipient Issue   & Direction Problem & System Problem & Update Contact & Any Logistical Issue & Cost & Time Taken (minutes)   \\\\\\\\ \\\\midrule\n",
    "Llama 3                & {}                & {}            & {}          & {}        & {}                 & \\\\$0.00 & 360 \\\\\\\\\n",
    "GPT 3.5 Turbo          & {}                & {}            & {}          & {}        & {}         & \\\\$0.34 & 10  \\\\\\\\\n",
    "GPT 4o Mini            & {}                & {}            & {}          & {}        & {}                 & \\\\$0.11 & 10  \\\\\\\\\n",
    "GPT 4o                 & {}                & {}            & {}          & {}        & {}                 & \\\\$3.74 & 15  \\\\\\\\ \\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "}}\n",
    "\\\\end{{table*}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[]\n",
      "\\scalebox{0.85}{\n",
      "\\begin{tabular}{@{}lllll@{}}\n",
      "\\toprule\n",
      "\\multirow{2}{*}{Model} & \\multicolumn{4}{c}{Donor Issues (F1)}      \\\\ \\cmidrule(lr){2-5}\n",
      "                       & Inadequate Food & Earlier Pickup & Other Donor Problem & Any Donor Issue \\\\ \\midrule\n",
      "Llama 3                & 0.51            & 0.52         & 0.52              & 0.60         \\\\\n",
      "GPT 3.5 Turbo          & 0.76            & 0.67         & 0.57              & 0.73            \\\\\n",
      "GPT 4o Mini            & 0.81            & 0.83         & 0.58              & 0.73           \\\\\n",
      "GPT 4o                 & 0.82            & 0.83         & 0.40              & 0.71             \\\\ \\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n",
      "\n",
      "\\begin{table*}[]\n",
      "\\scalebox{0.85}{\n",
      "\\begin{tabular}{@{}lccccccc@{}}\n",
      "\\toprule\n",
      "\\multirow{2}{*}{Model} & \\multicolumn{1}{c}{Recipient Issues (F1)} & \\multicolumn{4}{c}{Logistical Issues (F1)} & \\multicolumn{2}{c}{Other Info}                   \\\\ \\cmidrule(lr){2-2} \\cmidrule(lr){3-6} \\cmidrule(lr){7-8}\n",
      "                       & Any Recipient Issue   & Direction Problem & System Problem & Update Contact & Any Logistical Issue & Cost & Time Taken (minutes)   \\\\ \\midrule\n",
      "Llama 3                & 0.47                & 0.39            & 0.53          & 0.00        & 0.41                 & \\$0.00 & 360 \\\\\n",
      "GPT 3.5 Turbo          & 0.58                & 0.72            & 0.80          & 0.56        & 0.70         & \\$0.34 & 10  \\\\\n",
      "GPT 4o Mini            & 0.63                & 0.83            & 0.80          & 0.60        & 0.86                 & \\$0.11 & 10  \\\\\n",
      "GPT 4o                 & 0.70                & 0.90            & 0.88          & 1.00        & 0.94                 & \\$3.74 & 15  \\\\ \\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_formats = []\n",
    "for model in ['llama','gpt-3.5-turbo','gpt-4o-mini','gpt-4o']:\n",
    "    task_list = ['inadequate_food','earlier_pickup','donor_problem','any_donor_problem']#\n",
    "    for task in task_list:\n",
    "        all_formats.append(\"%.2f\"% data[model][task])\n",
    "for model in ['llama','gpt-3.5-turbo','gpt-4o-mini','gpt-4o']:\n",
    "    task_list = ['recipient_problem','direction_problem','system_problem','update_contact','any_system_problem']\n",
    "    for task in task_list:\n",
    "        all_formats.append(\"%.2f\"% data[model][task])\n",
    "print(table.format(*all_formats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_files = [\"gpt_35_annotations.json\",\"gpt_35_annotations_updated.json\"]#,\"gpt_4_annotations.json\"]\n",
    "consensus_file = \"consensus_annotations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_data = json.load(open(\"../../results/annotations/\"+consensus_file))\n",
    "consensus_data['annotations'] = sorted(consensus_data['annotations'],key=lambda k: k['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = [i['id'] for i in consensus_data['annotations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gpt-3.5 turbo\n",
      "0.9044585987261146 inadequate_food\n",
      "0.29032258064516125 donor_problem\n",
      "0.64 recipient_problem\n",
      "0.391304347826087 info_update\n",
      "\n",
      "Model gpt-3.5 turbo\n",
      "0.8875 inadequate_food\n",
      "0.2641509433962264 donor_problem\n",
      "0.368421052631579 recipient_problem\n",
      "0.41025641025641024 info_update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for annotation_file in annotation_files:\n",
    "    annotations = json.load(open(\"../../results/annotations/\"+annotation_file))\n",
    "    annotations['annotations'] = sorted(annotations['annotations'],key=lambda k: k['id'])\n",
    "    assert [i['id'] for i in annotations['annotations']] == all_id\n",
    "    print(\"Model {}\".format(annotations['parameters']['model']))\n",
    "\n",
    "    keys = ['inadequate_food', 'donor_problem', 'recipient_problem', 'info_update']\n",
    "    for k in keys:\n",
    "        all_annotation_values = [i[k] for i in annotations['annotations']]\n",
    "        all_consensus_values = [i[k] for i in consensus_data['annotations']]\n",
    "\n",
    "        f1 = f1_score(all_consensus_values,all_annotation_values)\n",
    "        print(f1,k)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_json = json.load(open(\"../../results/annotations/scored_instructions.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'logistics': 3, 'contact': 7, 'unhelpful': 1, 'directions': 4})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_count = Counter([i['category'] for i in annotated_json])\n",
    "category_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'side': 'donor',\n",
       " 'location_id': 123,\n",
       " 'comment': 'Giant eagle says only staurday Sunday and monday for 412 food rescue.   They said remove them from other days.  \\r\\n',\n",
       " 'old_instruction': \"Please enter the 412 Food Rescue PIN into scanner: 65428. Please do not share the PIN # with staff--it is our electronic signature! . Please call store when you're on your way to confirm donation. Ask for Bakery to confirm a donation. \",\n",
       " 'new_instruction': \"Please enter the 412 Food Rescue PIN into scanner: 65428. Please do not share the PIN # with staff--it is our electronic signature! . Please call store when you're on your way to confirm donation. Ask for Bakery to confirm a donation. Only available for pickup on Saturday, Sunday, and Monday.\",\n",
       " 'informativeness': 1,\n",
       " 'clarity': 1,\n",
       " 'helpfulness': 1,\n",
       " 'truthfulness': 1,\n",
       " 'category': 'logistics'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informativeness 1.0\n",
      "clarity 0.9333333333333333\n",
      "helpfulness 0.9333333333333333\n",
      "truthfulness 1.0\n"
     ]
    }
   ],
   "source": [
    "metrics = ['informativeness','clarity','helpfulness','truthfulness']\n",
    "for m in metrics:\n",
    "    print(m,Counter([i[m] for i in annotated_json])[1]/len(annotated_json))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
