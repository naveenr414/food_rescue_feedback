{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from feedback.plotting import *\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import pipeline\n",
    "from together import Together\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_columns = [\"update_contact\",\"inadequate_food\", \"earlier_pickup\",\"system_problem\",\"direction_problem\",\"recipient_problem\",\"donor_problem\",\"positive_comment\"]\n",
    "nice_names = [\"Update Contact\",\"Inadequate Food\",\"Earlier Pickup\",\"System Problem\",\"Direction Problem\",\"Recipient Problem\",\"Donor Problem\",\"Positive Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.read_csv(\"../../data/annotations/pre_deploy_eval.csv\")\n",
    "eval_dataset = eval_dataset[eval_dataset[\"annotator\"] == \"naveen\"][[\"volunteer_comment\",\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = pd.read_csv(\"../../data/annotations/pre_deploy_eval.csv\")\n",
    "groundtruth = groundtruth[groundtruth[\"annotator\"] == \"naveen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv(\"../../data/annotations/training.csv\")\n",
    "training_by_column = {}\n",
    "for col in eval_columns:\n",
    "    training_by_column[col] = training_dataset.copy()[training_dataset[col] != -1][[\"volunteer_comment\",\"id\",col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Based Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_recipient_names = pd.read_csv(\"../../data/annotations/donor_recipient_annotated_names.csv\")\n",
    "dataset_merged = eval_dataset.merge(\n",
    "    donor_recipient_names,\n",
    "    left_on='id',\n",
    "    right_on='delivery_id',\n",
    "    how='left'  # or 'inner' if you only want matches\n",
    ")\n",
    "tasks = ['recipient_problem', 'inadequate_food', 'donor_problem', \n",
    "            'direction_problem','earlier_pickup','system_problem',\n",
    "            'update_contact','positive_comment']\n",
    "together_models = [\"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"]\n",
    "\n",
    "prompts = {}\n",
    "for t in tasks:\n",
    "    prompts[t] = open(\"../../data/prompts/{}.txt\".format(t)).read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Together(api_key=together_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Model deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n",
      "On Rescue 1 out of 126\n",
      "On Rescue 2 out of 126\n",
      "On Rescue 3 out of 126\n",
      "On Rescue 4 out of 126\n",
      "On Rescue 5 out of 126\n",
      "On Rescue 6 out of 126\n",
      "On Rescue 7 out of 126\n",
      "On Rescue 8 out of 126\n",
      "On Rescue 9 out of 126\n",
      "On Rescue 10 out of 126\n",
      "On Rescue 11 out of 126\n",
      "On Rescue 12 out of 126\n",
      "On Rescue 13 out of 126\n",
      "On Rescue 14 out of 126\n",
      "On Rescue 15 out of 126\n",
      "On Rescue 16 out of 126\n",
      "On Rescue 17 out of 126\n",
      "On Rescue 18 out of 126\n",
      "On Rescue 19 out of 126\n",
      "On Rescue 20 out of 126\n",
      "On Rescue 21 out of 126\n",
      "On Rescue 22 out of 126\n",
      "On Rescue 23 out of 126\n",
      "On Rescue 24 out of 126\n",
      "On Rescue 25 out of 126\n",
      "On Rescue 26 out of 126\n",
      "On Rescue 27 out of 126\n",
      "On Rescue 28 out of 126\n",
      "On Rescue 29 out of 126\n",
      "On Rescue 30 out of 126\n",
      "On Rescue 31 out of 126\n",
      "On Rescue 32 out of 126\n",
      "On Rescue 33 out of 126\n",
      "On Rescue 34 out of 126\n",
      "On Rescue 35 out of 126\n",
      "On Rescue 36 out of 126\n",
      "On Rescue 37 out of 126\n",
      "On Rescue 38 out of 126\n",
      "On Rescue 39 out of 126\n",
      "On Rescue 40 out of 126\n",
      "On Rescue 41 out of 126\n",
      "On Rescue 42 out of 126\n",
      "On Rescue 43 out of 126\n",
      "On Rescue 44 out of 126\n",
      "On Rescue 45 out of 126\n",
      "On Rescue 46 out of 126\n",
      "On Rescue 47 out of 126\n",
      "On Rescue 48 out of 126\n",
      "On Rescue 49 out of 126\n",
      "On Rescue 50 out of 126\n",
      "On Rescue 51 out of 126\n",
      "On Rescue 52 out of 126\n",
      "On Rescue 53 out of 126\n",
      "On Rescue 54 out of 126\n",
      "On Rescue 55 out of 126\n",
      "On Rescue 56 out of 126\n",
      "On Rescue 57 out of 126\n",
      "On Rescue 58 out of 126\n",
      "On Rescue 59 out of 126\n",
      "On Rescue 60 out of 126\n",
      "On Rescue 61 out of 126\n",
      "On Rescue 62 out of 126\n",
      "On Rescue 63 out of 126\n",
      "On Rescue 64 out of 126\n",
      "On Rescue 65 out of 126\n",
      "On Rescue 66 out of 126\n",
      "On Rescue 67 out of 126\n",
      "On Rescue 68 out of 126\n",
      "On Rescue 69 out of 126\n",
      "On Rescue 70 out of 126\n",
      "On Rescue 71 out of 126\n",
      "On Rescue 72 out of 126\n",
      "On Rescue 73 out of 126\n",
      "On Rescue 74 out of 126\n",
      "On Rescue 75 out of 126\n",
      "On Rescue 76 out of 126\n",
      "On Rescue 77 out of 126\n",
      "On Rescue 78 out of 126\n",
      "On Rescue 79 out of 126\n",
      "On Rescue 80 out of 126\n",
      "On Rescue 81 out of 126\n",
      "On Rescue 82 out of 126\n",
      "On Rescue 83 out of 126\n",
      "On Rescue 84 out of 126\n",
      "On Rescue 85 out of 126\n",
      "On Rescue 86 out of 126\n",
      "On Rescue 87 out of 126\n",
      "On Rescue 88 out of 126\n",
      "On Rescue 89 out of 126\n",
      "On Rescue 90 out of 126\n",
      "On Rescue 91 out of 126\n",
      "On Rescue 92 out of 126\n",
      "On Rescue 93 out of 126\n",
      "On Rescue 94 out of 126\n",
      "On Rescue 95 out of 126\n",
      "On Rescue 96 out of 126\n",
      "On Rescue 97 out of 126\n",
      "On Rescue 98 out of 126\n",
      "On Rescue 99 out of 126\n",
      "On Rescue 100 out of 126\n",
      "On Rescue 101 out of 126\n",
      "On Rescue 102 out of 126\n",
      "On Rescue 103 out of 126\n",
      "On Rescue 104 out of 126\n",
      "On Rescue 105 out of 126\n",
      "On Rescue 106 out of 126\n",
      "On Rescue 107 out of 126\n",
      "On Rescue 108 out of 126\n",
      "On Rescue 109 out of 126\n",
      "On Rescue 110 out of 126\n",
      "On Rescue 111 out of 126\n",
      "On Rescue 112 out of 126\n",
      "On Rescue 113 out of 126\n",
      "On Rescue 114 out of 126\n",
      "On Rescue 115 out of 126\n",
      "On Rescue 116 out of 126\n",
      "On Rescue 117 out of 126\n",
      "On Rescue 118 out of 126\n",
      "On Rescue 119 out of 126\n",
      "On Rescue 120 out of 126\n",
      "On Rescue 121 out of 126\n",
      "On Rescue 122 out of 126\n",
      "On Rescue 123 out of 126\n",
      "On Rescue 124 out of 126\n",
      "On Rescue 125 out of 126\n",
      "On Rescue 126 out of 126\n",
      "On Model meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\n",
      "On Rescue 1 out of 126\n",
      "Error processing feedback 0 for task recipient_problem: Error code: 402 - {\"message\": \"Credit limit exceeded. Please navigate to https://api.together.xyz/settings/billing to add credit or upgrade your plan.\", \"type_\": \"credit_limit\"}\n",
      "On Rescue 2 out of 126\n",
      "On Rescue 3 out of 126\n",
      "On Rescue 4 out of 126\n",
      "On Rescue 5 out of 126\n",
      "On Rescue 6 out of 126\n",
      "On Rescue 7 out of 126\n",
      "On Rescue 8 out of 126\n",
      "On Rescue 9 out of 126\n",
      "On Rescue 10 out of 126\n",
      "On Rescue 11 out of 126\n",
      "On Rescue 12 out of 126\n",
      "On Rescue 13 out of 126\n",
      "On Rescue 14 out of 126\n",
      "On Rescue 15 out of 126\n",
      "On Rescue 16 out of 126\n",
      "On Rescue 17 out of 126\n",
      "On Rescue 18 out of 126\n",
      "On Rescue 19 out of 126\n",
      "On Rescue 20 out of 126\n",
      "On Rescue 21 out of 126\n",
      "On Rescue 22 out of 126\n",
      "On Rescue 23 out of 126\n",
      "On Rescue 24 out of 126\n",
      "On Rescue 25 out of 126\n",
      "On Rescue 26 out of 126\n",
      "On Rescue 27 out of 126\n",
      "On Rescue 28 out of 126\n",
      "On Rescue 29 out of 126\n",
      "On Rescue 30 out of 126\n",
      "On Rescue 31 out of 126\n",
      "On Rescue 32 out of 126\n",
      "On Rescue 33 out of 126\n",
      "On Rescue 34 out of 126\n",
      "On Rescue 35 out of 126\n",
      "On Rescue 36 out of 126\n",
      "On Rescue 37 out of 126\n",
      "On Rescue 38 out of 126\n",
      "On Rescue 39 out of 126\n",
      "On Rescue 40 out of 126\n",
      "On Rescue 41 out of 126\n",
      "On Rescue 42 out of 126\n",
      "On Rescue 43 out of 126\n",
      "On Rescue 44 out of 126\n",
      "On Rescue 45 out of 126\n",
      "On Rescue 46 out of 126\n",
      "On Rescue 47 out of 126\n",
      "On Rescue 48 out of 126\n",
      "On Rescue 49 out of 126\n",
      "On Rescue 50 out of 126\n",
      "On Rescue 51 out of 126\n",
      "On Rescue 52 out of 126\n",
      "On Rescue 53 out of 126\n",
      "On Rescue 54 out of 126\n",
      "On Rescue 55 out of 126\n",
      "On Rescue 56 out of 126\n",
      "On Rescue 57 out of 126\n",
      "On Rescue 58 out of 126\n",
      "On Rescue 59 out of 126\n",
      "On Rescue 60 out of 126\n",
      "On Rescue 61 out of 126\n",
      "On Rescue 62 out of 126\n",
      "On Rescue 63 out of 126\n",
      "On Rescue 64 out of 126\n",
      "On Rescue 65 out of 126\n",
      "On Rescue 66 out of 126\n",
      "On Rescue 67 out of 126\n",
      "On Rescue 68 out of 126\n",
      "On Rescue 69 out of 126\n",
      "On Rescue 70 out of 126\n",
      "On Rescue 71 out of 126\n",
      "On Rescue 72 out of 126\n",
      "On Rescue 73 out of 126\n",
      "On Rescue 74 out of 126\n",
      "On Rescue 75 out of 126\n",
      "On Rescue 76 out of 126\n",
      "On Rescue 77 out of 126\n",
      "On Rescue 78 out of 126\n",
      "On Rescue 79 out of 126\n",
      "On Rescue 80 out of 126\n",
      "On Rescue 81 out of 126\n",
      "On Rescue 82 out of 126\n",
      "On Rescue 83 out of 126\n",
      "On Rescue 84 out of 126\n",
      "On Rescue 85 out of 126\n",
      "On Rescue 86 out of 126\n",
      "On Rescue 87 out of 126\n",
      "On Rescue 88 out of 126\n",
      "On Rescue 89 out of 126\n",
      "On Rescue 90 out of 126\n",
      "On Rescue 91 out of 126\n",
      "On Rescue 92 out of 126\n",
      "On Rescue 93 out of 126\n",
      "On Rescue 94 out of 126\n",
      "On Rescue 95 out of 126\n",
      "On Rescue 96 out of 126\n",
      "On Rescue 97 out of 126\n",
      "On Rescue 98 out of 126\n",
      "On Rescue 99 out of 126\n",
      "On Rescue 100 out of 126\n",
      "On Rescue 101 out of 126\n",
      "On Rescue 102 out of 126\n",
      "On Rescue 103 out of 126\n",
      "On Rescue 104 out of 126\n",
      "On Rescue 105 out of 126\n",
      "On Rescue 106 out of 126\n",
      "On Rescue 107 out of 126\n",
      "On Rescue 108 out of 126\n",
      "On Rescue 109 out of 126\n",
      "On Rescue 110 out of 126\n",
      "On Rescue 111 out of 126\n",
      "On Rescue 112 out of 126\n",
      "On Rescue 113 out of 126\n",
      "On Rescue 114 out of 126\n",
      "On Rescue 115 out of 126\n",
      "On Rescue 116 out of 126\n",
      "On Rescue 117 out of 126\n",
      "On Rescue 118 out of 126\n",
      "On Rescue 119 out of 126\n",
      "On Rescue 120 out of 126\n",
      "On Rescue 121 out of 126\n",
      "On Rescue 122 out of 126\n",
      "On Rescue 123 out of 126\n",
      "On Rescue 124 out of 126\n",
      "On Rescue 125 out of 126\n",
      "On Rescue 126 out of 126\n"
     ]
    }
   ],
   "source": [
    "predictions_by_model = [[{} for i in range(len(dataset_merged))] for i in range(len(together_models))]\n",
    "\n",
    "for idx,model in enumerate(together_models):\n",
    "    print(\"On Model {}\".format(model))\n",
    "    for i in range(len(dataset_merged)):\n",
    "        comment = (\n",
    "            f'For this rescue, the donor is {dataset_merged.loc[i, \"donor_name\"]};'\n",
    "            f' the recipient is {dataset_merged.loc[i, \"recipient_name\"]}.'\n",
    "            f' Comment: {dataset_merged.loc[i, \"volunteer_comment\"]}'\n",
    "        )\n",
    "\n",
    "        print(\"On Rescue {} out of {}\".format(i+1,len(dataset_merged)))\n",
    "        predictions_by_model[idx][i]['volunteer_comment'] = dataset_merged.loc[i, \"volunteer_comment\"]\n",
    "\n",
    "        for task in tasks:\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompts[task] + comment}],\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                output = response.choices[0].message.content\n",
    "                output = re.search('\\{.*\\}',output,re.DOTALL).group(0)\n",
    "                feedback_info = json.loads(output)\n",
    "                predictions_by_model[idx][i][task] = feedback_info[task]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing feedback {i} for task {task}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = predictions_by_model[0][0].keys()\n",
    "\n",
    "for i,model in enumerate(together_models):\n",
    "    file_name = \"{}.csv\".format(model.replace(\"/\",\"_\"))\n",
    "    dataframe = pd.DataFrame(predictions_by_model[i])\n",
    "    dataframe.to_csv('../../results/evaluation/{}'.format(file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = os.environ.get(\"POSTGRES_DB\")\n",
    "username = os.environ.get(\"POSTGRES_USER\")\n",
    "password = os.environ.get(\"POSTGRES_PASSWORD\") \n",
    "ip_address = os.environ.get(\"DATABASE_HOST\") \n",
    "port = os.environ.get(\"DATABASE_PORT\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_models = [\"gpt-4o-mini\",\"gpt-4o\"]\n",
    "client = openai.OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['update_contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Model gpt-4o-mini\n",
      "On Rescue 1 out of 126\n",
      "On Rescue 2 out of 126\n",
      "On Rescue 3 out of 126\n",
      "On Rescue 4 out of 126\n",
      "On Rescue 5 out of 126\n",
      "On Rescue 6 out of 126\n",
      "On Rescue 7 out of 126\n",
      "On Rescue 8 out of 126\n",
      "On Rescue 9 out of 126\n",
      "On Rescue 10 out of 126\n",
      "On Rescue 11 out of 126\n",
      "On Rescue 12 out of 126\n",
      "On Rescue 13 out of 126\n",
      "On Rescue 14 out of 126\n",
      "On Rescue 15 out of 126\n",
      "On Rescue 16 out of 126\n",
      "On Rescue 17 out of 126\n",
      "On Rescue 18 out of 126\n",
      "On Rescue 19 out of 126\n",
      "On Rescue 20 out of 126\n",
      "On Rescue 21 out of 126\n",
      "On Rescue 22 out of 126\n",
      "On Rescue 23 out of 126\n",
      "On Rescue 24 out of 126\n",
      "On Rescue 25 out of 126\n",
      "On Rescue 26 out of 126\n",
      "On Rescue 27 out of 126\n",
      "On Rescue 28 out of 126\n",
      "On Rescue 29 out of 126\n",
      "On Rescue 30 out of 126\n",
      "On Rescue 31 out of 126\n",
      "On Rescue 32 out of 126\n",
      "On Rescue 33 out of 126\n",
      "On Rescue 34 out of 126\n",
      "On Rescue 35 out of 126\n",
      "On Rescue 36 out of 126\n",
      "On Rescue 37 out of 126\n",
      "On Rescue 38 out of 126\n",
      "On Rescue 39 out of 126\n",
      "On Rescue 40 out of 126\n",
      "On Rescue 41 out of 126\n",
      "On Rescue 42 out of 126\n",
      "On Rescue 43 out of 126\n",
      "On Rescue 44 out of 126\n",
      "On Rescue 45 out of 126\n",
      "On Rescue 46 out of 126\n",
      "On Rescue 47 out of 126\n",
      "On Rescue 48 out of 126\n",
      "On Rescue 49 out of 126\n",
      "On Rescue 50 out of 126\n",
      "On Rescue 51 out of 126\n",
      "On Rescue 52 out of 126\n",
      "On Rescue 53 out of 126\n",
      "On Rescue 54 out of 126\n",
      "On Rescue 55 out of 126\n",
      "On Rescue 56 out of 126\n",
      "On Rescue 57 out of 126\n",
      "On Rescue 58 out of 126\n",
      "On Rescue 59 out of 126\n",
      "On Rescue 60 out of 126\n",
      "On Rescue 61 out of 126\n",
      "On Rescue 62 out of 126\n",
      "On Rescue 63 out of 126\n",
      "On Rescue 64 out of 126\n",
      "On Rescue 65 out of 126\n",
      "On Rescue 66 out of 126\n",
      "On Rescue 67 out of 126\n",
      "On Rescue 68 out of 126\n",
      "On Rescue 69 out of 126\n",
      "On Rescue 70 out of 126\n",
      "On Rescue 71 out of 126\n",
      "On Rescue 72 out of 126\n",
      "On Rescue 73 out of 126\n",
      "On Rescue 74 out of 126\n",
      "On Rescue 75 out of 126\n",
      "On Rescue 76 out of 126\n",
      "On Rescue 77 out of 126\n",
      "On Rescue 78 out of 126\n",
      "On Rescue 79 out of 126\n",
      "On Rescue 80 out of 126\n",
      "On Rescue 81 out of 126\n",
      "On Rescue 82 out of 126\n",
      "On Rescue 83 out of 126\n",
      "On Rescue 84 out of 126\n",
      "On Rescue 85 out of 126\n",
      "On Rescue 86 out of 126\n",
      "On Rescue 87 out of 126\n",
      "On Rescue 88 out of 126\n",
      "On Rescue 89 out of 126\n",
      "On Rescue 90 out of 126\n",
      "On Rescue 91 out of 126\n",
      "On Rescue 92 out of 126\n",
      "On Rescue 93 out of 126\n",
      "On Rescue 94 out of 126\n",
      "On Rescue 95 out of 126\n",
      "On Rescue 96 out of 126\n",
      "On Rescue 97 out of 126\n",
      "On Rescue 98 out of 126\n",
      "On Rescue 99 out of 126\n",
      "On Rescue 100 out of 126\n",
      "On Rescue 101 out of 126\n",
      "On Rescue 102 out of 126\n",
      "On Rescue 103 out of 126\n",
      "On Rescue 104 out of 126\n",
      "On Rescue 105 out of 126\n",
      "On Rescue 106 out of 126\n",
      "On Rescue 107 out of 126\n",
      "On Rescue 108 out of 126\n",
      "On Rescue 109 out of 126\n",
      "On Rescue 110 out of 126\n",
      "On Rescue 111 out of 126\n",
      "On Rescue 112 out of 126\n",
      "On Rescue 113 out of 126\n",
      "On Rescue 114 out of 126\n",
      "On Rescue 115 out of 126\n",
      "On Rescue 116 out of 126\n",
      "On Rescue 117 out of 126\n",
      "On Rescue 118 out of 126\n",
      "On Rescue 119 out of 126\n",
      "On Rescue 120 out of 126\n",
      "On Rescue 121 out of 126\n",
      "On Rescue 122 out of 126\n",
      "On Rescue 123 out of 126\n",
      "On Rescue 124 out of 126\n",
      "On Rescue 125 out of 126\n",
      "On Rescue 126 out of 126\n"
     ]
    }
   ],
   "source": [
    "predictions_by_model = [[{} for i in range(len(dataset_merged))] for i in range(len(gpt_models))]\n",
    "\n",
    "for idx,model in enumerate(gpt_models):\n",
    "    print(\"On Model {}\".format(model))\n",
    "    for i in range(len(dataset_merged)):\n",
    "        comment = (\n",
    "            f'For this rescue, the donor is {dataset_merged.loc[i, \"donor_name\"]};'\n",
    "            f' the recipient is {dataset_merged.loc[i, \"recipient_name\"]}.'\n",
    "            f' Comment: {dataset_merged.loc[i, \"volunteer_comment\"]}'\n",
    "        )\n",
    "\n",
    "        print(\"On Rescue {} out of {}\".format(i+1,len(dataset_merged)))\n",
    "        predictions_by_model[idx][i]['volunteer_comment'] = dataset_merged.loc[i, \"volunteer_comment\"]\n",
    "        predictions_by_model[idx][i]['id'] = dataset_merged.loc[i, \"id\"]\n",
    "\n",
    "        for task in tasks:\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompts[task] + comment}],\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                output = response.choices[0].message.content\n",
    "                output = re.search('\\{.*\\}',output,re.DOTALL).group(0)\n",
    "                feedback_info = json.loads(output)\n",
    "                predictions_by_model[idx][i][task] = feedback_info[task]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing feedback {i} for task {task}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = predictions_by_model[0][0].keys()\n",
    "\n",
    "for i,model in enumerate(together_models):\n",
    "    file_name = \"{}.csv\".format(model.replace(\"/\",\"_\"))\n",
    "    dataframe = pd.DataFrame(predictions_by_model[i])\n",
    "    dataframe.to_csv('../../results/evaluation/{}'.format(file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablations = [\"no_few_shot\",\"no_guidelines\",\"no_explanations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Rescue 1 out of 126\n",
      "On Rescue 2 out of 126\n",
      "On Rescue 3 out of 126\n",
      "On Rescue 4 out of 126\n",
      "On Rescue 5 out of 126\n",
      "On Rescue 6 out of 126\n",
      "On Rescue 7 out of 126\n",
      "On Rescue 8 out of 126\n",
      "On Rescue 9 out of 126\n",
      "On Rescue 10 out of 126\n",
      "On Rescue 11 out of 126\n",
      "On Rescue 12 out of 126\n",
      "On Rescue 13 out of 126\n",
      "On Rescue 14 out of 126\n",
      "On Rescue 15 out of 126\n",
      "On Rescue 16 out of 126\n",
      "On Rescue 17 out of 126\n",
      "On Rescue 18 out of 126\n",
      "On Rescue 19 out of 126\n",
      "On Rescue 20 out of 126\n",
      "On Rescue 21 out of 126\n",
      "On Rescue 22 out of 126\n",
      "On Rescue 23 out of 126\n",
      "On Rescue 24 out of 126\n",
      "On Rescue 25 out of 126\n",
      "On Rescue 26 out of 126\n",
      "On Rescue 27 out of 126\n",
      "On Rescue 28 out of 126\n",
      "On Rescue 29 out of 126\n",
      "On Rescue 30 out of 126\n",
      "On Rescue 31 out of 126\n",
      "On Rescue 32 out of 126\n",
      "On Rescue 33 out of 126\n",
      "On Rescue 34 out of 126\n",
      "On Rescue 35 out of 126\n",
      "On Rescue 36 out of 126\n",
      "On Rescue 37 out of 126\n",
      "On Rescue 38 out of 126\n",
      "On Rescue 39 out of 126\n",
      "On Rescue 40 out of 126\n",
      "On Rescue 41 out of 126\n",
      "On Rescue 42 out of 126\n",
      "On Rescue 43 out of 126\n",
      "On Rescue 44 out of 126\n",
      "On Rescue 45 out of 126\n",
      "On Rescue 46 out of 126\n",
      "On Rescue 47 out of 126\n",
      "On Rescue 48 out of 126\n",
      "On Rescue 49 out of 126\n",
      "On Rescue 50 out of 126\n",
      "On Rescue 51 out of 126\n",
      "On Rescue 52 out of 126\n",
      "On Rescue 53 out of 126\n",
      "On Rescue 54 out of 126\n",
      "On Rescue 55 out of 126\n",
      "On Rescue 56 out of 126\n",
      "On Rescue 57 out of 126\n",
      "On Rescue 58 out of 126\n",
      "On Rescue 59 out of 126\n",
      "On Rescue 60 out of 126\n",
      "On Rescue 61 out of 126\n",
      "On Rescue 62 out of 126\n",
      "On Rescue 63 out of 126\n",
      "On Rescue 64 out of 126\n",
      "On Rescue 65 out of 126\n",
      "On Rescue 66 out of 126\n",
      "On Rescue 67 out of 126\n",
      "On Rescue 68 out of 126\n",
      "On Rescue 69 out of 126\n",
      "On Rescue 70 out of 126\n",
      "On Rescue 71 out of 126\n",
      "On Rescue 72 out of 126\n",
      "On Rescue 73 out of 126\n",
      "On Rescue 74 out of 126\n",
      "On Rescue 75 out of 126\n",
      "On Rescue 76 out of 126\n",
      "On Rescue 77 out of 126\n",
      "On Rescue 78 out of 126\n",
      "On Rescue 79 out of 126\n",
      "On Rescue 80 out of 126\n",
      "On Rescue 81 out of 126\n",
      "On Rescue 82 out of 126\n",
      "On Rescue 83 out of 126\n",
      "On Rescue 84 out of 126\n",
      "On Rescue 85 out of 126\n",
      "On Rescue 86 out of 126\n",
      "On Rescue 87 out of 126\n",
      "On Rescue 88 out of 126\n",
      "On Rescue 89 out of 126\n",
      "On Rescue 90 out of 126\n",
      "On Rescue 91 out of 126\n",
      "On Rescue 92 out of 126\n",
      "On Rescue 93 out of 126\n",
      "On Rescue 94 out of 126\n",
      "On Rescue 95 out of 126\n",
      "On Rescue 96 out of 126\n",
      "On Rescue 97 out of 126\n",
      "On Rescue 98 out of 126\n",
      "On Rescue 99 out of 126\n",
      "On Rescue 100 out of 126\n",
      "On Rescue 101 out of 126\n",
      "On Rescue 102 out of 126\n",
      "On Rescue 103 out of 126\n",
      "On Rescue 104 out of 126\n",
      "On Rescue 105 out of 126\n",
      "On Rescue 106 out of 126\n",
      "On Rescue 107 out of 126\n",
      "On Rescue 108 out of 126\n",
      "On Rescue 109 out of 126\n",
      "On Rescue 110 out of 126\n",
      "On Rescue 111 out of 126\n",
      "On Rescue 112 out of 126\n",
      "On Rescue 113 out of 126\n",
      "On Rescue 114 out of 126\n",
      "On Rescue 115 out of 126\n",
      "On Rescue 116 out of 126\n",
      "On Rescue 117 out of 126\n",
      "On Rescue 118 out of 126\n",
      "On Rescue 119 out of 126\n",
      "On Rescue 120 out of 126\n",
      "On Rescue 121 out of 126\n",
      "On Rescue 122 out of 126\n",
      "On Rescue 123 out of 126\n",
      "On Rescue 124 out of 126\n",
      "On Rescue 125 out of 126\n",
      "On Rescue 126 out of 126\n",
      "On Rescue 1 out of 126\n",
      "On Rescue 2 out of 126\n",
      "On Rescue 3 out of 126\n",
      "On Rescue 4 out of 126\n",
      "On Rescue 5 out of 126\n",
      "On Rescue 6 out of 126\n",
      "On Rescue 7 out of 126\n",
      "On Rescue 8 out of 126\n",
      "On Rescue 9 out of 126\n",
      "On Rescue 10 out of 126\n",
      "On Rescue 11 out of 126\n",
      "On Rescue 12 out of 126\n",
      "On Rescue 13 out of 126\n",
      "On Rescue 14 out of 126\n",
      "On Rescue 15 out of 126\n",
      "On Rescue 16 out of 126\n",
      "On Rescue 17 out of 126\n",
      "On Rescue 18 out of 126\n",
      "On Rescue 19 out of 126\n",
      "On Rescue 20 out of 126\n",
      "On Rescue 21 out of 126\n",
      "On Rescue 22 out of 126\n",
      "On Rescue 23 out of 126\n",
      "On Rescue 24 out of 126\n",
      "On Rescue 25 out of 126\n",
      "On Rescue 26 out of 126\n",
      "On Rescue 27 out of 126\n",
      "On Rescue 28 out of 126\n",
      "On Rescue 29 out of 126\n",
      "On Rescue 30 out of 126\n",
      "On Rescue 31 out of 126\n",
      "On Rescue 32 out of 126\n",
      "On Rescue 33 out of 126\n",
      "On Rescue 34 out of 126\n",
      "On Rescue 35 out of 126\n",
      "On Rescue 36 out of 126\n",
      "On Rescue 37 out of 126\n",
      "On Rescue 38 out of 126\n",
      "On Rescue 39 out of 126\n",
      "On Rescue 40 out of 126\n",
      "On Rescue 41 out of 126\n",
      "On Rescue 42 out of 126\n",
      "On Rescue 43 out of 126\n",
      "On Rescue 44 out of 126\n",
      "On Rescue 45 out of 126\n",
      "On Rescue 46 out of 126\n",
      "On Rescue 47 out of 126\n",
      "On Rescue 48 out of 126\n",
      "On Rescue 49 out of 126\n",
      "On Rescue 50 out of 126\n",
      "On Rescue 51 out of 126\n",
      "On Rescue 52 out of 126\n",
      "On Rescue 53 out of 126\n",
      "On Rescue 54 out of 126\n",
      "On Rescue 55 out of 126\n",
      "On Rescue 56 out of 126\n",
      "On Rescue 57 out of 126\n",
      "On Rescue 58 out of 126\n",
      "On Rescue 59 out of 126\n",
      "On Rescue 60 out of 126\n",
      "On Rescue 61 out of 126\n",
      "On Rescue 62 out of 126\n",
      "On Rescue 63 out of 126\n",
      "On Rescue 64 out of 126\n",
      "On Rescue 65 out of 126\n",
      "On Rescue 66 out of 126\n",
      "On Rescue 67 out of 126\n",
      "On Rescue 68 out of 126\n",
      "On Rescue 69 out of 126\n",
      "On Rescue 70 out of 126\n",
      "On Rescue 71 out of 126\n",
      "On Rescue 72 out of 126\n",
      "On Rescue 73 out of 126\n",
      "On Rescue 74 out of 126\n",
      "On Rescue 75 out of 126\n",
      "On Rescue 76 out of 126\n",
      "On Rescue 77 out of 126\n",
      "On Rescue 78 out of 126\n",
      "On Rescue 79 out of 126\n",
      "On Rescue 80 out of 126\n",
      "On Rescue 81 out of 126\n",
      "On Rescue 82 out of 126\n",
      "On Rescue 83 out of 126\n",
      "On Rescue 84 out of 126\n",
      "On Rescue 85 out of 126\n",
      "On Rescue 86 out of 126\n",
      "On Rescue 87 out of 126\n",
      "On Rescue 88 out of 126\n",
      "On Rescue 89 out of 126\n",
      "On Rescue 90 out of 126\n",
      "On Rescue 91 out of 126\n",
      "On Rescue 92 out of 126\n",
      "On Rescue 93 out of 126\n",
      "On Rescue 94 out of 126\n",
      "On Rescue 95 out of 126\n",
      "On Rescue 96 out of 126\n",
      "On Rescue 97 out of 126\n",
      "On Rescue 98 out of 126\n",
      "On Rescue 99 out of 126\n",
      "On Rescue 100 out of 126\n",
      "On Rescue 101 out of 126\n",
      "On Rescue 102 out of 126\n",
      "On Rescue 103 out of 126\n",
      "On Rescue 104 out of 126\n",
      "On Rescue 105 out of 126\n",
      "On Rescue 106 out of 126\n",
      "On Rescue 107 out of 126\n",
      "On Rescue 108 out of 126\n",
      "On Rescue 109 out of 126\n",
      "On Rescue 110 out of 126\n",
      "On Rescue 111 out of 126\n",
      "On Rescue 112 out of 126\n",
      "On Rescue 113 out of 126\n",
      "On Rescue 114 out of 126\n",
      "On Rescue 115 out of 126\n",
      "On Rescue 116 out of 126\n",
      "On Rescue 117 out of 126\n",
      "On Rescue 118 out of 126\n",
      "On Rescue 119 out of 126\n",
      "On Rescue 120 out of 126\n",
      "On Rescue 121 out of 126\n",
      "On Rescue 122 out of 126\n",
      "On Rescue 123 out of 126\n",
      "On Rescue 124 out of 126\n",
      "On Rescue 125 out of 126\n",
      "On Rescue 126 out of 126\n",
      "On Rescue 1 out of 126\n",
      "On Rescue 2 out of 126\n",
      "On Rescue 3 out of 126\n",
      "On Rescue 4 out of 126\n",
      "On Rescue 5 out of 126\n",
      "On Rescue 6 out of 126\n",
      "On Rescue 7 out of 126\n",
      "On Rescue 8 out of 126\n",
      "On Rescue 9 out of 126\n",
      "On Rescue 10 out of 126\n",
      "On Rescue 11 out of 126\n",
      "On Rescue 12 out of 126\n",
      "On Rescue 13 out of 126\n",
      "On Rescue 14 out of 126\n",
      "On Rescue 15 out of 126\n",
      "On Rescue 16 out of 126\n",
      "On Rescue 17 out of 126\n",
      "On Rescue 18 out of 126\n",
      "On Rescue 19 out of 126\n",
      "On Rescue 20 out of 126\n",
      "On Rescue 21 out of 126\n",
      "On Rescue 22 out of 126\n",
      "On Rescue 23 out of 126\n",
      "On Rescue 24 out of 126\n",
      "On Rescue 25 out of 126\n",
      "On Rescue 26 out of 126\n",
      "On Rescue 27 out of 126\n",
      "On Rescue 28 out of 126\n",
      "On Rescue 29 out of 126\n",
      "On Rescue 30 out of 126\n",
      "On Rescue 31 out of 126\n",
      "On Rescue 32 out of 126\n",
      "On Rescue 33 out of 126\n",
      "On Rescue 34 out of 126\n",
      "On Rescue 35 out of 126\n",
      "On Rescue 36 out of 126\n",
      "On Rescue 37 out of 126\n",
      "On Rescue 38 out of 126\n",
      "On Rescue 39 out of 126\n",
      "On Rescue 40 out of 126\n",
      "On Rescue 41 out of 126\n",
      "On Rescue 42 out of 126\n",
      "On Rescue 43 out of 126\n",
      "On Rescue 44 out of 126\n",
      "On Rescue 45 out of 126\n",
      "On Rescue 46 out of 126\n",
      "On Rescue 47 out of 126\n",
      "On Rescue 48 out of 126\n",
      "On Rescue 49 out of 126\n",
      "On Rescue 50 out of 126\n",
      "On Rescue 51 out of 126\n",
      "On Rescue 52 out of 126\n",
      "On Rescue 53 out of 126\n",
      "On Rescue 54 out of 126\n",
      "On Rescue 55 out of 126\n",
      "On Rescue 56 out of 126\n",
      "On Rescue 57 out of 126\n",
      "On Rescue 58 out of 126\n",
      "On Rescue 59 out of 126\n",
      "On Rescue 60 out of 126\n",
      "On Rescue 61 out of 126\n",
      "On Rescue 62 out of 126\n",
      "On Rescue 63 out of 126\n",
      "On Rescue 64 out of 126\n",
      "On Rescue 65 out of 126\n",
      "On Rescue 66 out of 126\n",
      "On Rescue 67 out of 126\n",
      "On Rescue 68 out of 126\n",
      "On Rescue 69 out of 126\n",
      "On Rescue 70 out of 126\n",
      "On Rescue 71 out of 126\n",
      "On Rescue 72 out of 126\n",
      "On Rescue 73 out of 126\n",
      "On Rescue 74 out of 126\n",
      "On Rescue 75 out of 126\n",
      "On Rescue 76 out of 126\n",
      "On Rescue 77 out of 126\n",
      "On Rescue 78 out of 126\n",
      "On Rescue 79 out of 126\n",
      "On Rescue 80 out of 126\n",
      "On Rescue 81 out of 126\n",
      "On Rescue 82 out of 126\n",
      "On Rescue 83 out of 126\n",
      "On Rescue 84 out of 126\n",
      "On Rescue 85 out of 126\n",
      "On Rescue 86 out of 126\n",
      "On Rescue 87 out of 126\n",
      "On Rescue 88 out of 126\n",
      "On Rescue 89 out of 126\n",
      "On Rescue 90 out of 126\n",
      "On Rescue 91 out of 126\n",
      "On Rescue 92 out of 126\n",
      "On Rescue 93 out of 126\n",
      "On Rescue 94 out of 126\n",
      "On Rescue 95 out of 126\n",
      "On Rescue 96 out of 126\n",
      "On Rescue 97 out of 126\n",
      "On Rescue 98 out of 126\n",
      "On Rescue 99 out of 126\n",
      "On Rescue 100 out of 126\n",
      "On Rescue 101 out of 126\n",
      "On Rescue 102 out of 126\n",
      "On Rescue 103 out of 126\n",
      "On Rescue 104 out of 126\n",
      "On Rescue 105 out of 126\n",
      "On Rescue 106 out of 126\n",
      "On Rescue 107 out of 126\n",
      "On Rescue 108 out of 126\n",
      "On Rescue 109 out of 126\n",
      "On Rescue 110 out of 126\n",
      "On Rescue 111 out of 126\n",
      "On Rescue 112 out of 126\n",
      "On Rescue 113 out of 126\n",
      "On Rescue 114 out of 126\n",
      "On Rescue 115 out of 126\n",
      "On Rescue 116 out of 126\n",
      "On Rescue 117 out of 126\n",
      "On Rescue 118 out of 126\n",
      "On Rescue 119 out of 126\n",
      "On Rescue 120 out of 126\n",
      "On Rescue 121 out of 126\n",
      "On Rescue 122 out of 126\n",
      "On Rescue 123 out of 126\n",
      "On Rescue 124 out of 126\n",
      "On Rescue 125 out of 126\n",
      "On Rescue 126 out of 126\n"
     ]
    }
   ],
   "source": [
    "predictions_by_model = [[{} for i in range(len(dataset_merged))] for i in range(len(ablations))]\n",
    "for idx,a in enumerate(ablations):\n",
    "    for i in range(len(dataset_merged)):\n",
    "        comment = (\n",
    "            f'For this rescue, the donor is {dataset_merged.loc[i, \"donor_name\"]};'\n",
    "            f' the recipient is {dataset_merged.loc[i, \"recipient_name\"]}.'\n",
    "            f' Comment: {dataset_merged.loc[i, \"volunteer_comment\"]}'\n",
    "        )\n",
    "\n",
    "        print(\"On Rescue {} out of {}\".format(i+1,len(dataset_merged)))\n",
    "        predictions_by_model[idx][i]['volunteer_comment'] = dataset_merged.loc[i, \"volunteer_comment\"]\n",
    "\n",
    "        for task in tasks:\n",
    "            basic_ending = \"Responses should be formatted in JSON to maintain uniformity and clarity across reports. The response should have two keys: {} and explanation. \\n Now, it’s your turn. \\n Analyze the following rescue: \\n\".format(task)\n",
    "\n",
    "            if a == \"no_few_shot\":\n",
    "                full_prompt = prompts[task].split(\"Example Comment Analysis:\")[0] + \"Now, it’s your turn. \\n Analyze the following rescue; note that the JSON should have two keys: {} and explanation: \\n\".format(task)\n",
    "            elif a == \"no_guidelines\":\n",
    "                full_prompt = prompts[task].split(\"Notes:\")[0] + \"\\n Example Comment Analysis\\n\"+prompts[task].split(\"Example Comment Analysis:\")[1]\n",
    "                full_prompt = full_prompt.split(\"Now, it’s your turn\")[0]+basic_ending\n",
    "            elif a == \"no_explanations\":\n",
    "                full_prompt = prompts[task].split(\"\\n\")\n",
    "                full_prompt = \"\\n\".join([i for i in full_prompt if '\"explanation\"' not in i])\n",
    "\n",
    "\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model='gpt-4o-mini',\n",
    "                    messages=[{\"role\": \"user\", \"content\": full_prompt + \"\\n\"+comment}],\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                output = response.choices[0].message.content\n",
    "                output = re.search('\\{.*\\}',output,re.DOTALL).group(0)\n",
    "                feedback_info = json.loads(output)\n",
    "                predictions_by_model[idx][i][task] = feedback_info[task]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing feedback {i} for task {task}: {e}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = predictions_by_model[0][0].keys()\n",
    "\n",
    "for i,a in enumerate(ablations):\n",
    "    file_name = \"ablation_{}.csv\".format(a.replace(\"/\",\"_\"))\n",
    "    dataframe = pd.DataFrame(predictions_by_model[i])\n",
    "    dataframe.to_csv('../../results/evaluation/{}'.format(file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-LLM Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prediction = np.random.random((len(eval_dataset),len(eval_columns)))\n",
    "random_prediction = random_prediction.round()\n",
    "\n",
    "result_df = eval_dataset.copy()\n",
    "\n",
    "# Add the prediction columns\n",
    "for i, col_name in enumerate(eval_columns):\n",
    "    result_df[col_name] = random_prediction[:, i].astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('../../results/evaluation/random.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prediction = np.random.random((len(eval_dataset),len(eval_columns)))\n",
    "base_rates = list(groundtruth[eval_columns].mean())\n",
    "for i in range(len(eval_columns)):\n",
    "    random_prediction[:,i] = random_prediction[:,i] < base_rates[i]\n",
    "\n",
    "random_prediction = random_prediction.round()\n",
    "\n",
    "result_df = eval_dataset.copy()\n",
    "\n",
    "# Add the prediction columns\n",
    "for i, col_name in enumerate(eval_columns):\n",
    "    result_df[col_name] = random_prediction[:, i].astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('../../results/evaluation/random_marginal.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_model = [{} for i in range(len(dataset_merged))]\n",
    "for d in eval_columns:\n",
    "    pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))\n",
    "    pipeline.fit(training_by_column[d]['volunteer_comment'], training_by_column[d][d])\n",
    "\n",
    "    for i in range(len(dataset_merged)):\n",
    "        volunteer_comment = dataset_merged.loc[i,'volunteer_comment']\n",
    "        predictions_by_model[i]['volunteer_comment'] = volunteer_comment\n",
    "        y_pred = pipeline.predict([volunteer_comment])\n",
    "        predictions_by_model[i][d] = y_pred[0]\n",
    "predictions_by_model = pd.DataFrame(predictions_by_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_model.to_csv('../../results/evaluation/tf_idf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cea77bca833492592e229eb45285bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:12, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126f975edeae4a4aba24003da543dd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:20, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaa258cf4d6485e811187450b26c15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:10, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f52c4af4fc47e698e15454f121ccc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:10, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109aead1a12140818f0c8d65545bb3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:12, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763b5b9024504841b70db37836ad34b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:12, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac70813ff1d48a8be52841860e6009c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:23, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601651cc984f4458bc8acce23d678a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:10, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.070300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_by_model = [{} for i in range(len(eval_dataset))]\n",
    "eval_dataset = pd.read_csv(\"../../data/annotations/pre_deploy_eval.csv\")\n",
    "eval_dataset = eval_dataset[eval_dataset[\"annotator\"] == \"naveen\"][[\"volunteer_comment\",\"id\"]]\n",
    "for task in eval_columns:\n",
    "    task_name = task\n",
    "    df = training_by_column[task_name][[\"volunteer_comment\", task_name]].rename(columns={task_name: \"label\"})\n",
    "    train_ds = Dataset.from_pandas(df.reset_index(drop=True))\n",
    "    checkpoint = \"distilbert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "    # Tokenize\n",
    "    def tokenize_function(example):\n",
    "        return tokenizer(example[\"volunteer_comment\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "    train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_steps=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    disable_tqdm=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 🔍 Evaluate on new sentence\n",
    "    for i in range(len(eval_dataset)):\n",
    "        input_text = eval_dataset.loc[i,\"volunteer_comment\"]\n",
    "        predictions_by_model[i][\"volunteer_comment\"] = input_text\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to('cuda:0')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            pred = torch.argmax(probs, dim=-1).item()\n",
    "            predictions_by_model[i][task_name] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions_by_model).to_csv('../../results/evaluation/distilbert.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
